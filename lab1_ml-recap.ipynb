{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab1 - Introduction + Neural Networks + PyTorch recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plan for today\n",
    "\n",
    "1. Get to know course rules, timetable, etc.\n",
    "2. Briefly recap our ML knowledge:\n",
    "    * implement basic logistic regression from scratch\n",
    "    * get (re)accustomed with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Course logistics\n",
    "\n",
    "Let's go over [the course page](https://github.com/gmum/wzum-24) on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Logistic regression from scratch\n",
    "\n",
    "We will tackle the problem of **classification**, i.e. prediction of a discrete value (class):\n",
    "\n",
    "$$\n",
    "f(x) = y, y \\in \\{0...N\\}\n",
    "$$\n",
    "\n",
    "The most basic variant of this is **binary** classification: $y \\in \\{0, 1\\}$. We will focus on that for the time being.\n",
    "\n",
    "**Logistic regression** is a model which predicts the probability that a given example belongs to the class 1:\n",
    "\n",
    "$$\n",
    "g(x) = \\hat{p}(y = 1 | x )\n",
    "$$\n",
    "\n",
    "**Questions for you:**\n",
    "* what is the probability that $y=0$?\n",
    "* in the multi-class case, how many outputs will the model have?\n",
    "* what conditions must the model outputs satisfy?\n",
    "\n",
    "As an example, we will work with a breast cancer prediction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "|details-start|\n",
      "**References**\n",
      "|details-split|\n",
      "\n",
      "- W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "  for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "  Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "  San Jose, CA, 1993.\n",
      "- O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "  prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "  July-August 1995.\n",
      "- W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "  to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "  163-171.\n",
      "\n",
      "|details-end|\n"
     ]
    }
   ],
   "source": [
    "print(load_breast_cancer().DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array shapes [(512, 30), (57, 30), (512,), (57,)]\n",
      "y values [0 1] [0 1]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_val, y_train, y_val= train_test_split(X, y, train_size=0.9)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "print(\"array shapes\", [t.shape for t in [X_train, X_val, y_train, y_val]])\n",
    "print(\"y values\", np.unique(y_train), np.unique(y_val) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Linear vs logistic regression\n",
    "\n",
    "We need to transform a vector of 30 features into a value $\\in (0,1)$. Can we use linear regression for that?\n",
    "\n",
    "![classification_regression](https://raw.githubusercontent.com/aghbit/BIT_AI/master/3_logistic_regression/img/clas_reg.png)\n",
    "\n",
    "Recall that in linear regression $f(x) \\in \\mathbb{R} $ is defined as:\n",
    "$$\n",
    "f(x) = w^T x + b\n",
    "$$\n",
    "\n",
    "Where $w, b$ are trainable parameters.\n",
    "\n",
    "In logistic regression, we will need to squash the output, so that $f(x) \\in [0,1]$. A convenient way to do this is the **sigmoid** function:\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(-inf) = 0.0\n",
      "sigmoid(0) = 0.5\n",
      "sigmoid(1) = 0.7310585786300049\n",
      "sigmoid(inf) = 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "for x in [\n",
    "   -np.inf,\n",
    "    0,\n",
    "    1,\n",
    "    np.inf\n",
    "]:\n",
    "    print(f\"sigmoid({x}) = {sigmoid(x)}\")\n",
    "\n",
    "x = np.linspace(-10, 10)\n",
    "\n",
    "plt.plot(x, sigmoid(x))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To sum it up, in case of binary classification:\n",
    "$$\n",
    "\\hat{p}(y=1 | x) = \\sigma(w^Tx + b)\n",
    "$$\n",
    "\n",
    "What about the loss function which can train such a model?\n",
    "\n",
    "We'll use a logarithmic loss function which quite nicely captures an intuition, that we want the predictions datapoints which should be predicted as $0$ as close to $0$ as possible, and, analogically, predictions which should be $1$, as close to $1$ as possible:\n",
    "\n",
    "$$ L = \\frac{-1}{n}\\Big(\\sum_{i=0}^n y^{(i)}\\log{f(x^{(i)})} + (1-y^{(i)})\\log{(1-f(x^{(i)}))} \\Big)$$\n",
    "\n",
    "This function is called **Binary Cross-Entropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(1e-6, 1 - (1e-6), 1000)\n",
    "\n",
    "plt.plot(x, -np.log(1 - x), label=\"loss when y = 0\")\n",
    "plt.plot(x, -np.log(x), label=\"loss when y = 1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task for you: implement the binary cross-entropy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def binary_cross_entropy(x, y, w, b) -> float:\n",
    "    \"\"\"\n",
    "    All arguments are numpy arrays with shapes:\n",
    "        x: [N, F]\n",
    "        y: [N]\n",
    "        w: [F, 1]\n",
    "        b: [1]\n",
    "\n",
    "    Returns:\n",
    "        The value of binary cross-entropy (a single number).\n",
    "    \"\"\"\n",
    "    #30 in features\n",
    "    z = np.dot(x,w) + b\n",
    "    fx=sigmoid(z)\n",
    "    print(f'fx.shape: {fx.shape}, y.shape: {y.shape}')\n",
    "    L = -1/y.size*np.sum(np.copy(y)*np.log(fx) + (1-np.copy(y))*(1-fx))\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to train the parameters $w, b$ of our model, we need to calculate the gradients of loss with regard to those parameters:\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial w} \\text{ and } \\frac{\\partial L}{\\partial b} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task for you: implement the function which calculates $\\frac{\\partial L}{\\partial w}$ and $\\frac{\\partial L}{\\partial b}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_gradients(x, y, w, b) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    All arguments are numpy arrays with shapes:\n",
    "        x: [N, F]\n",
    "        y: [N]\n",
    "        w: [F, 1]\n",
    "        b: [1]\n",
    "\n",
    "    Returns:\n",
    "        The gradients of loss L with respect to `w` and `b`. Their shapes should be identical to the shapes of `w` and `b`, respectively.\n",
    "    \"\"\"\n",
    "    a=(x/(np.exp(b+np.dot(x,w))+1))\n",
    "    b=(1/(np.exp(b+np.dot(x,w))+1) )\n",
    "    return (a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With the gradient calculation implemented, we should be able to train our model with the **Gradient Descent** method.\n",
    "\n",
    "With a good choice of learning rate, you should be able to achieve around 90% validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1000,) and (30,1) not aligned: 1000 (dim 0) != 30 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m history \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m---> 12\u001b[0m     y_pred_train \u001b[38;5;241m=\u001b[39m sigmoid(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b) \u001b[38;5;66;03m# calculate predictions based on x, w, and b (don't forget sigmoid!)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     y_pred_train \u001b[38;5;241m=\u001b[39m (y_pred_train \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     14\u001b[0m     train_accuracy \u001b[38;5;241m=\u001b[39m (y_pred_train\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y_train)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1000,) and (30,1) not aligned: 1000 (dim 0) != 30 (dim 0)"
     ]
    }
   ],
   "source": [
    "w = np.random.randn(30, 1) * 0.01\n",
    "b = np.random.randn(1)* 0.01\n",
    "# how should we initialize w and b?\n",
    "\n",
    "lr = 1e-1\n",
    "# how big should be the learning rate?\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    \n",
    "    y_pred_train = sigmoid(np.dot(x,w) + b) # calculate predictions based on x, w, and b (don't forget sigmoid!)\n",
    "    y_pred_train = (y_pred_train > 0.5).astype(int)\n",
    "    train_accuracy = (y_pred_train.reshape(-1) == y_train).mean()\n",
    "    \n",
    "    y_pred_val = sigmoid(X_val @ w + b) # calculate predictions based on x, w, and b (don't forget sigmoid!)\n",
    "    y_pred_val = (y_pred_val > 0.5).astype(int)\n",
    "    val_accuracy = (y_pred_val.reshape(-1) == y_val).mean()\n",
    "    \n",
    "    l_train = binary_cross_entropy(X_train, y_train, w=w, b=b)\n",
    "    dw, db = calculate_gradients(X_train, y_train, w=w, b=b)\n",
    "\n",
    "    w = w - lr * dw.T # assign new value of w based on gradient dw\n",
    "    b = b - lr * db.T # assign new value of b based on gradient db\n",
    "    \n",
    "    elem = dict(epoch=epoch, loss=l_train, train_accuracy=train_accuracy, val_accuracy=val_accuracy)\n",
    "    history.append(elem)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot([h[\"epoch\"] for h in history], [h[\"loss\"] for h in history], label=\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot([h[\"epoch\"] for h in history], [h[\"train_accuracy\"] for h in history], label=\"train acc\")\n",
    "plt.plot([h[\"epoch\"] for h in history], [h[\"val_accuracy\"] for h in history], label=\"val acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Logistic regression with PyTorch automatic differentiation / loss / optimization tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task for you: initialize a logistic regression PyTorch model and train it\n",
    "\n",
    "You should achieve around 90% validation accuracy.\n",
    "\n",
    "**Hint: if you think you did everything right, but your model can't learn, check whether the dimensions of the tensors throughout the training are correct.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    # we need a sequence of two pytorch layers for a basic logistic regression model - which ones?\n",
    ")\n",
    "opt = SGD(model.parameters(), lr=1e-1)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "print({\n",
    "    name: p.shape\n",
    "    for (name, p) in model.named_parameters()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    ### YOUR CODE HERE ###\n",
    "    y_pred_train = ... # make predictions for train set\n",
    "    y_pred_val = ... # make_predictions for val set\n",
    "    \n",
    "    # calculate loss\n",
    "    l_train = ...\n",
    "    # calculate gradients with respect to l_train\n",
    "    \n",
    "    # perform the optimization step with the optimizer\n",
    "    \n",
    "    #######################\n",
    "    \n",
    "    train_accuracy = ((y_pred_train.detach().numpy() > 0.5) == y_train).mean()\n",
    "    val_accuracy = ((y_pred_val.detach().numpy() > 0.5) == y_val).mean()\n",
    "\n",
    "    elem = dict(epoch=epoch, loss=l_train.item(), train_accuracy=train_accuracy, val_accuracy=val_accuracy)\n",
    "    history.append(elem)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "plt.plot([h[\"epoch\"] for h in history], [h[\"loss\"] for h in history], label=\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot([h[\"epoch\"] for h in history], [h[\"train_accuracy\"] for h in history], label=\"train acc\")\n",
    "plt.plot([h[\"epoch\"] for h in history], [h[\"val_accuracy\"] for h in history], label=\"val acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. FashionMNIST: a bigger task\n",
    "\n",
    "Let's now train a neural net on a more challenging, multi-label FashionMNIST task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms as tv\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: load the dataset and visualize some examples along with their classes\n",
    "* what is the shape of a single example from the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = FashionMNIST('./data', train=True, target_transform=None, download=True, transform=tv.ToTensor()) # transform the data from PIL image to a tensor\n",
    "ds_test = FashionMNIST('./data', train=False, target_transform=None, download=True, transform=tv.ToTensor()) # transform the data from PIL image to a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize 10 examples from the dataset, along with their class numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "\n",
    "train_dl = DataLoader(ds, batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(ds_test, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: implement and train a neural network with two linear layers and ReLU activation between them. \n",
    "\n",
    "You should achieve at least 80% validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # initialize the layers of the network\n",
    "        # what is the size of the input?\n",
    "        # what is the output size?\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # process x through:\n",
    "        # 1) first layer\n",
    "        # 2) relu activation\n",
    "        # 3) second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FashionNN() # actually initialize the net\n",
    "loss_fn = ... # what loss do we use for multilabel classification?\n",
    "opt = torch.optim.Adam(net.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 10\n",
    "\n",
    "for i in range(number_of_epochs):\n",
    "    train_loss = 0\n",
    "    for iteration, (X_train, y_train) in enumerate(train_dl):\n",
    "        \n",
    "        # perform optimization on the train set and calculate the total train loss\n",
    "        ...\n",
    "        \n",
    "        \n",
    "    val_loss = 0\n",
    "    y_predicted = []\n",
    "    y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for iteration, (X_val, y_val) in enumerate(valid_dl):\n",
    "            # perform predictions on the validation set and gather them to calculate accuracy\n",
    "            \n",
    "            y_pred = net(X_val)\n",
    "            loss = loss_fn(y_pred, y_val)\n",
    "            val_loss += loss.item()\n",
    "            y_pred = y_pred.argmax(dim=1)\n",
    "            y_true.extend(y_val.numpy())\n",
    "            y_predicted.extend(y_pred.numpy())\n",
    "    \n",
    "            \n",
    "    val_acc = accuracy_score(y_true, y_predicted)\n",
    "    print(f'#Epoch: {i}, train loss: {train_loss}, val loss: {val_loss}, val_acc: {val_acc}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
