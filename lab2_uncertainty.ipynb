{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPY1-2Q5tCtF"
   },
   "source": [
    "# Lab 2 - uncertainty in neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8BHBn76tCtI"
   },
   "source": [
    "# Plan for today\n",
    "\n",
    "\n",
    "1. Learn about **Expected Calibration Error**\n",
    "    * measure it for an example neural network\n",
    "    * minimize it for that network\n",
    "2. See it's usages in practice:\n",
    "    * out-of-distribution detection\n",
    "    * early exit networks\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1_IXd7-vnZV"
   },
   "source": [
    "**Question 1** - can you think of a real-life example where knowing the prediction uncertainty is important?\n",
    "\n",
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kEOcjR0stCtK"
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch import nn\n",
    "import torch\n",
    "from typing import List\n",
    "from torchvision.datasets import FashionMNIST, CIFAR10\n",
    "from torchvision import transforms as tv\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.models import vgg16, vgg16_bn, resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "crDkmJH8uPyC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "#import ssl\n",
    "import json\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zKPTemJcJg7"
   },
   "source": [
    "Today, we will work with the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset, with a small twist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VmRBEEmHue3G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trans = transform=tv.Compose([tv.ToTensor(), tv.Normalize(mean=[0.5, 0.5, 0.5], std=[1,1,1])])\n",
    "ds = CIFAR10('./data', train=True, target_transform=None, download=True, transform=trans)# transform the data from PIL image to a tensor\n",
    "ds_test = CIFAR10('./data', train=False, target_transform=None, download=True, transform=trans) # transform the data from PIL image to a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQBmBbEucCTP"
   },
   "source": [
    "We will split the data in half, to simulate two data distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gc1vvScmwLo5"
   },
   "outputs": [],
   "source": [
    "# INCLUDED_CLASSES = [0, 2, 4, 6, 8]\n",
    "\n",
    "ds_train_included = Subset(ds, indices = [i for (i, c) in enumerate(ds.targets) if c %2 == 0 ])\n",
    "ds_train_excluded = Subset(ds, indices = [i for (i, c) in enumerate(ds.targets) if c %2 != 0])\n",
    "\n",
    "ds_test_included = Subset(ds_test, indices = [i for (i, c) in enumerate(ds_test.targets) if c %2 == 0 ])\n",
    "ds_test_excluded = Subset(ds_test, indices = [i for (i, c) in enumerate(ds_test.targets) if c %2 != 0 ])\n",
    "\n",
    "batch_size=128\n",
    "\n",
    "dl_train_in = DataLoader(ds_train_included, batch_size, shuffle=True)\n",
    "dl_train_ex = DataLoader(ds_train_excluded, batch_size, shuffle=True)\n",
    "\n",
    "dl_test_in = DataLoader(ds_test_included, batch_size, shuffle=False)\n",
    "dl_test_ex = DataLoader(ds_test_excluded, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Np9c7hriAXr"
   },
   "source": [
    "## 1 - Expected calibration error\n",
    "\n",
    "\n",
    "A perfectly calibrated model will have the following property: **A prediction with score $p$ means that there is a $p$ chance, that the model is right**.\n",
    "\n",
    "\n",
    "Expected Calibration Error (ECE) is a way to measure how well a model estimates **it's own uncertainty**, i.e. how well it is calibrated:\n",
    "\n",
    "To calculate it, we need to:\n",
    "* make predictions with our model\n",
    "* divide the predictions into bins $B_m$ based on their score (confidence)\n",
    "* calculate the accuracy of predictions in each $B_m$\n",
    "* measure the difference between the confidence of each bin and it's mean accuracy\n",
    "\n",
    "Formally:\n",
    "\n",
    "$$\n",
    "ECE = \\sum_{i=1}^M \\frac{|B_m|}{N} \\left| acc(B_m) - conf(B_m) \\right|.\n",
    "$$\n",
    "\n",
    "A useful way to visualize the model calibration is to plot a histogram of prediction scores and a reliability diagram, e.g:\n",
    "\n",
    "![reliability](https://drive.google.com/uc?id=1K1VdWAX1HU5xXbQ-Ya3TTcoGTfjuPM9C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mdIH1KVqJ1L"
   },
   "source": [
    "\n",
    "Unfortunately, models trained with softmax are not guaranteed to be well-calibrated.\n",
    "\n",
    "### Task for you - calculate ECE and draw a reliability diagram\n",
    "\n",
    "Below, there is a basic neural network definition with configurable depth and an example training loop.\n",
    "\n",
    "Please train this network on CIFAR-10. Afterwards, run predictions on a validation dataset, calculate the ECE and visualize the predictions histogram and the reliabilility diagram (you should produce figures similar to the ones above).\n",
    "\n",
    "You can repeat this for three different network setups by introducing various modifications, e.g.\n",
    "\n",
    "* changing network depth / hidden sizes (the easiest, should be enough to notice something)\n",
    "* adding batchnorm to the network\n",
    "* adding $l2$ regularization\n",
    "\n",
    "Please calculate the ECE and produce visualizations for all three networks. Then, briefly summarize what you did and how it influenced the calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vbSHwkTwtCtO"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self, hidden_sizes: List[int], downsize_steps: List[int], in_hw: int = 32, n_classes: int = 10):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      hidden sizes - hidden size of each consecutive convolution\n",
    "      downsize_steps - numbers of convolutions for which there will be stride = 2\n",
    "      in_hw - size of the input image\n",
    "      n_classes - number of output classes\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "\n",
    "    assert len(hidden_sizes) >= 1\n",
    "\n",
    "    self.conv1 = nn.Conv2d(3, hidden_sizes[0], 3, padding=1)\n",
    "\n",
    "    convs = []\n",
    "\n",
    "    for i, hs in enumerate(hidden_sizes[:-1]):\n",
    "      hs_next = hidden_sizes[i+1]\n",
    "      stride = 2 if i+1 in downsize_steps else 1\n",
    "      convs.append(\n",
    "          nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hs, hs_next, 3, padding=1, stride=stride),\n",
    "        )\n",
    "      )\n",
    "    self.convs = nn.Sequential(*convs)\n",
    "\n",
    "    dhw = in_hw // (2 ** len(downsize_steps))\n",
    "\n",
    "    out_dim = dhw * dhw * hidden_sizes[-1]\n",
    "    self.out = nn.Sequential(\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(out_dim, n_classes)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "\n",
    "    for i, c in self.convs:\n",
    "      x = c(x)\n",
    "    return self.out(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "VNAMQigAtCtQ"
   },
   "outputs": [],
   "source": [
    "def train_net(net, number_of_epochs: int = 20, lr: float = 0.001, weight_decay=0):\n",
    "  net = net.to(device)\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  opt = torch.optim.Adam(net.parameters(), weight_decay=weight_decay, lr=lr)\n",
    "\n",
    "  epoch_progress = list(range(number_of_epochs))#tqdm(list(range(number_of_epochs)))\n",
    "  for i in epoch_progress:\n",
    "      train_loss = 0\n",
    "      y_train_predicted = []\n",
    "      y_train_true = []\n",
    "      net.train()\n",
    "      for iteration, (X_train, y_train) in enumerate(dl_train_in):#tqdm(enumerate(dl_train_in), f\"Training epoch {i}\", total=len(dl_train_in), leave=False):\n",
    "          # notice we are training / testing on dl_train_in - the same distribution of data!\n",
    "          X_train, y_train = [t.to(device) for t in [X_train, y_train]]\n",
    "          opt.zero_grad()\n",
    "          y_pred = net(X_train)\n",
    "          loss = loss_fn(y_pred, y_train)\n",
    "          loss.backward()\n",
    "          opt.step()\n",
    "          train_loss += loss.item()\n",
    "          y_train_predicted.extend(y_pred.argmax(dim=1).cpu().numpy())\n",
    "          y_train_true.extend(y_train.cpu().numpy())\n",
    "\n",
    "\n",
    "      val_loss = 0\n",
    "      y_predicted = []\n",
    "      y_true = []\n",
    "\n",
    "      net.eval()\n",
    "      with torch.no_grad():\n",
    "          for iteration, (X_val, y_val) in enumerate(dl_test_in):#tqdm(enumerate(dl_test_in), f\"Val epoch {i}\",  total=len(dl_test_in), leave=False):\n",
    "              X_val, y_val = [t.to(device) for t in [X_val, y_val]]\n",
    "\n",
    "              y_pred = net(X_val)\n",
    "              loss = loss_fn(y_pred, y_val)\n",
    "              val_loss += loss.item()\n",
    "              y_pred = y_pred.argmax(dim=1)\n",
    "              y_true.extend(y_val.cpu().numpy())\n",
    "              y_predicted.extend(y_pred.cpu().numpy())\n",
    "\n",
    "      train_acc = accuracy_score(y_train_true, y_train_predicted)\n",
    "      val_acc = accuracy_score(y_true, y_predicted)\n",
    "      print(f'epoch: {i}, train_acc: {train_acc: .2f}, train loss: {train_loss:.2f}, val_acc: {val_acc: .2f}, val loss: {val_loss:.2f} ')\n",
    "      #epoch_progress.set_description(f'#Epoch: {i}, train loss: {train_loss:.2f}, train_acc: {train_acc:.2f}, val loss: {val_loss:.2f}, val_acc: {val_acc:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "cL9NthintcD6"
   },
   "outputs": [],
   "source": [
    "### caution! In order to get scores between (0,1), you'll need to apply softmax to network outputs!\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def ece(net, ds_loader: DataLoader) -> float:\n",
    "  ...\n",
    "  ### your code here\n",
    "  #criterion = nn.CrossEntropyLoss\n",
    "  bins_correct = torch.zeros(len(ds_loader.dataset)).to(device)\n",
    "  bins_total = torch.zeros(len(ds_loader.dataset)).to(device)\n",
    "  \n",
    "  #will comment each steps in case i may be wrong somewhere\n",
    "  net.eval()\n",
    "  with torch.no_grad():\n",
    "      for i, (X, y) in enumerate(ds_loader):\n",
    "          X, y = X.to(device), y.to(device) #load data to gpu\n",
    "\n",
    "          output = net(X) #vector of logits for classes\n",
    "          #loss = criterion(output, y)# loss\n",
    "\n",
    "          pred = output.argmax(dim=1) # predicted class\n",
    "          correct = pred.eq(y) # self-explanatory\n",
    "\n",
    "          confidence = torch.max(F.softmax(output, dim=1), dim=1)[0] # softmaxed output = confidence score, for the predicted class\n",
    "\n",
    "          bin_indices = (confidence * 10).long().to(device)  #we will have numbers in range (0,10) which will be integers, so can use it for indeksing\n",
    "\n",
    "          bins_correct.index_add_(0, bin_indices, correct.float().to(device))#we add information if there is correct prediction on index which represent confidence score.\n",
    "          bins_total.index_add_(0, bin_indices, torch.ones_like(correct).float().to(device))#we add ones to each bin\n",
    "\n",
    "  accuracies = bins_correct / (bins_total) #ratio of how often in certain bin was correct\n",
    "  #so for bin with index 0 accuracy should be the lowest, for big with index 9 in should be the hightest\n",
    "  confidences = bins_total / len(ds_loader.dataset)\n",
    "\n",
    "  ece_val = torch.abs(accuracies - confidences).dot(confidences)\n",
    "  return ece_val.item()\n",
    "\n",
    "def draw_scores_histogram(net, ds_loader: DataLoader, title: str=\"\"):\n",
    "  ...\n",
    "  ### your code here\n",
    "  scores = []\n",
    "  labels = []\n",
    "  net.eval()\n",
    "  with torch.no_grad():\n",
    "      for X, y in ds_loader:\n",
    "          X, y = X.to(device), y.to(device)\n",
    "          output = net(X)\n",
    "          probabilities = F.softmax(output, dim=1)\n",
    "          scores.extend(probabilities.max(dim=1)[0].cpu().numpy())\n",
    "          labels.extend(y.cpu().numpy())\n",
    "\n",
    "  plt.hist(scores, bins=10, alpha=0.5, color='blue')\n",
    "  plt.title(title)\n",
    "  plt.xlabel('Confidence')\n",
    "  plt.ylabel('Frequency')\n",
    "  plt.show()\n",
    "\n",
    "def draw_reliability_diagram(net, ds_loader: DataLoader, title: str=\"\"):\n",
    "\n",
    "  accuracies = []\n",
    "  confidences = []\n",
    "  net.eval()\n",
    "  with torch.no_grad():\n",
    "      for X, y in ds_loader:\n",
    "          X, y = X.to(device), y.to(device)\n",
    "          output = net(X)\n",
    "          probabilities = F.softmax(output, dim=1)\n",
    "          preds = probabilities.argmax(dim=1)\n",
    "          correct = preds.eq(y)\n",
    "          confidence = probabilities.max(dim=1)[0]\n",
    "          accuracies.extend(correct.cpu().numpy())\n",
    "          confidences.extend(confidence.cpu().numpy())\n",
    "\n",
    "  bin_boundaries = [i / 10.0 for i in range(11)]\n",
    "  bin_correct = [0] * 10\n",
    "  bin_total = [0] * 10\n",
    "\n",
    "  for i in range(len(confidences)):\n",
    "      bin_index = int(confidences[i] * 10)\n",
    "      bin_total[bin_index] += 1\n",
    "      if accuracies[i]:\n",
    "          bin_correct[bin_index] += 1\n",
    "\n",
    "  for i in range(10):\n",
    "      if bin_total[i] > 0:\n",
    "          bin_correct[i] /= bin_total[i]\n",
    "\n",
    "  plt.plot(bin_boundaries, bin_correct, marker='o', linestyle='-')\n",
    "  plt.plot(bin_boundaries, bin_boundaries, linestyle='--', color='gray')\n",
    "  plt.title(title)\n",
    "  plt.xlabel('Confidence')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.show()\n",
    "  ### your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "aIJ3E0wn2dVA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net 0\n",
      "epoch: 0, train_acc:  0.49, train loss: 233.17, val_acc:  0.60, val loss: 39.85 \n",
      "epoch: 1, train_acc:  0.64, train loss: 180.22, val_acc:  0.68, val loss: 33.28 \n",
      "epoch: 2, train_acc:  0.70, train loss: 156.97, val_acc:  0.73, val loss: 30.36 \n",
      "epoch: 3, train_acc:  0.73, train loss: 137.84, val_acc:  0.73, val loss: 29.70 \n",
      "epoch: 4, train_acc:  0.77, train loss: 123.36, val_acc:  0.74, val loss: 28.86 \n",
      "epoch: 5, train_acc:  0.79, train loss: 111.62, val_acc:  0.73, val loss: 29.83 \n",
      "epoch: 6, train_acc:  0.82, train loss: 98.40, val_acc:  0.72, val loss: 34.11 \n",
      "epoch: 7, train_acc:  0.84, train loss: 86.88, val_acc:  0.74, val loss: 30.39 \n",
      "epoch: 8, train_acc:  0.86, train loss: 77.04, val_acc:  0.74, val loss: 33.18 \n",
      "epoch: 9, train_acc:  0.87, train loss: 70.21, val_acc:  0.72, val loss: 37.25 \n",
      "epoch: 10, train_acc:  0.89, train loss: 61.02, val_acc:  0.73, val loss: 39.67 \n",
      "epoch: 11, train_acc:  0.90, train loss: 53.46, val_acc:  0.72, val loss: 42.85 \n",
      "epoch: 12, train_acc:  0.91, train loss: 48.28, val_acc:  0.73, val loss: 43.99 \n",
      "epoch: 13, train_acc:  0.91, train loss: 46.56, val_acc:  0.73, val loss: 45.18 \n",
      "epoch: 14, train_acc:  0.92, train loss: 40.48, val_acc:  0.72, val loss: 48.55 \n",
      "epoch: 15, train_acc:  0.93, train loss: 36.69, val_acc:  0.73, val loss: 51.28 \n",
      "epoch: 16, train_acc:  0.93, train loss: 37.68, val_acc:  0.72, val loss: 58.23 \n",
      "epoch: 17, train_acc:  0.95, train loss: 30.20, val_acc:  0.72, val loss: 56.84 \n",
      "epoch: 18, train_acc:  0.95, train loss: 28.84, val_acc:  0.73, val loss: 61.45 \n",
      "epoch: 19, train_acc:  0.95, train loss: 30.68, val_acc:  0.72, val loss: 67.10 \n",
      "nan\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m   train_net(net)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(ece(net, dl_test_in))\n\u001b[1;32m---> 19\u001b[0m \u001b[43mdraw_reliability_diagram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_test_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m draw_scores_histogram(net, dl_test_in, \u001b[38;5;28mstr\u001b[39m(i))\n",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36mdraw_reliability_diagram\u001b[1;34m(net, ds_loader, title)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(confidences)):\n\u001b[0;32m     78\u001b[0m     bin_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(confidences[i] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 79\u001b[0m     bin_total[bin_index] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accuracies[i]:\n\u001b[0;32m     81\u001b[0m         bin_correct[bin_index] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "net1 = Net([32, 32, 64, 64, 128, 128], [2, 4]).to(device) # you may start with this example network\n",
    "\n",
    "net2 = Net([32, 64, 128], [2]).to(device)\n",
    "net3 = Net([32, 32, 64, 64, 128, 128], [2, 4]).to(device) #has optimizer\n",
    "#optimarzerze\n",
    "\n",
    "for i, net in enumerate([\n",
    "            net1,\n",
    "            net2,\n",
    "            net3\n",
    "  ]):\n",
    "  print(\"Net\", i) #there is problem with devices\n",
    "  if(i==2):\n",
    "    train_net(net,weight_decay=0.1)\n",
    "  else:\n",
    "    train_net(net)\n",
    "\n",
    "  print(ece(net, dl_test_in))\n",
    "  draw_reliability_diagram(net, dl_test_in, str(i))\n",
    "  draw_scores_histogram(net, dl_test_in, str(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8Kkdtpq20uO"
   },
   "source": [
    "### **Question 2** - please summarize your experiments - what influences the good / bad calibration of the network?\n",
    "\n",
    "**YOUR ANSWER HERE**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAQUoueFbza4"
   },
   "source": [
    "## 2 - Out-of-distribution classification\n",
    "\n",
    "We have seen how the models work with umages of classes the model has learned to recognize.\n",
    "\n",
    "But what if we feed to the network images with the objects the model was not trained on?\n",
    "\n",
    "### Task for you - how does the model behave when processing images with unknown labels?\n",
    "Please draw the score histograms for the `dl_test_ex` dataset (the test dataset with excluded classes) for those three nets.\n",
    "\n",
    "**Question 3** - how do differently calibrated nets react to out-of-distribution images?\n",
    "\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEQ8QUHp2w7X"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m net \u001b[38;5;129;01min\u001b[39;00m [net1, net2]:\u001b[38;5;66;03m#, net3]:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m   \u001b[43mdraw_scores_histogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_test_ex\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mdraw_scores_histogram\u001b[1;34m(net, ds_loader, title)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m ds_loader:\n\u001b[0;32m     44\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 45\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     47\u001b[0m     scores\u001b[38;5;241m.\u001b[39mextend(probabilities\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32md:\\Programy\\Anaconda\\envs\\uczenie_reprezentacji\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Programy\\Anaconda\\envs\\uczenie_reprezentacji\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 40\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[0;32m     43\u001b[0m     x \u001b[38;5;241m=\u001b[39m c(x)\n",
      "File \u001b[1;32md:\\Programy\\Anaconda\\envs\\uczenie_reprezentacji\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Programy\\Anaconda\\envs\\uczenie_reprezentacji\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programy\\Anaconda\\envs\\uczenie_reprezentacji\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programy\\Anaconda\\envs\\uczenie_reprezentacji\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "for net in [net1, net2]:#, net3]:\n",
    "  draw_scores_histogram(net, dl_test_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJAVGWjG4OzC"
   },
   "source": [
    "## 3 - Early exit networks\n",
    "\n",
    "One of the interesting use cases of model uncertainty are early exit networks, e.g. [Shallow-Deep Networks (SDN)](https://arxiv.org/abs/1810.07052) or [Zero-Time-Waste](https://arxiv.org/abs/2106.05409):\n",
    "\n",
    "![SDN](https://drive.google.com/uc?id=1REU4cX92utasN3Eix40HMJnhQ2Tmftu6)\n",
    "\n",
    "The basic idea of SDN is to:\n",
    "* pretrain a base network (backbone)\n",
    "* attach linear probes (internal classifiers) to the internal blocks of the backbone and train them (without modifying the backbone further)\n",
    "* during inference, if the certainty of an internal classifier is high enough, output the prediction of that IC without further processing.\n",
    "\n",
    "### Task for you - play with SDN\n",
    "\n",
    "Below there is a modified implementation of the above neural net.\n",
    "\n",
    "**Coding**:\n",
    "* add necessary modifications in order to attach a linear layer to each backbone block and to return outputs from those internal classifiers during the forward pass\n",
    "    * you will need to add modifications to the code of the below network, as well as modify the training loop\n",
    "* train the basic part of the net (without the internal classifiers)\n",
    "* train the internal classifiers **(during this part we shouldn't train the rest of the network!)**\n",
    "\n",
    "**Expected results**:\n",
    "* for each internal classifier, plot the reliability diagram and scores histogram (you should draw similar plots as in section 1 for each IC)\n",
    "* plot the train/test accuracy of each internal classifier. Basically, you should end up with a plot like this:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=15OZD2pPvXIF2c8yG3vUI3FyjFsV1TYlH\" width=\"640\" height=\"400\" allow=\"autoplay\"></img>\n",
    "\n",
    "For the basic net, you may choose one of the previously checked architectures. You don't need to repeat the experiment with different architectures (though you're welcome to!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "xERQHmBR3k54"
   },
   "outputs": [],
   "source": [
    "class NetWithHeads(nn.Module):\n",
    "  def __init__(self, hidden_sizes: List[int], downsize_steps: List[int], in_hw: int = 32, n_classes: int = 10):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      hidden sizes - hidden size of each consecutive convolution\n",
    "      downsize_steps - numbers of convolutions for which there will be stride = 2\n",
    "      in_hw - size of the input image\n",
    "      n_classes - number of output classes\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "\n",
    "    assert len(hidden_sizes) >= 1\n",
    "\n",
    "    self.conv1 = nn.Conv2d(3, hidden_sizes[0], 3, padding=1)\n",
    "\n",
    "    convs = []\n",
    "    heads = []\n",
    "\n",
    "    for i, hs in enumerate(hidden_sizes[:-1]):\n",
    "      hs_next = hidden_sizes[i+1]\n",
    "      stride = 2 if i+1 in downsize_steps else 1\n",
    "      convs.append(\n",
    "          nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hs, hs_next, 3, padding=1, stride=stride),\n",
    "        )\n",
    "      )\n",
    "      ##### YOUR CODE HERE ####\n",
    "      \n",
    "      # for each internal convolution, initialize an internal classifier (a single linear layer)\n",
    "      # which will take the output from this convolution and perform classification (return N classes)\n",
    "      ####\n",
    "      self.internalOut = nn.Sequential(\n",
    "        nn.Linear(hs_next, n_classes)\n",
    "    )\n",
    "      heads.append(self.internalOut)\n",
    "\n",
    "\n",
    "    self.convs = nn.Sequential(*convs)\n",
    "\n",
    "    dhw = in_hw // (2 ** len(downsize_steps))\n",
    "\n",
    "    out_dim = dhw * dhw * hidden_sizes[-1]\n",
    "    self.out = nn.Sequential(\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(out_dim, n_classes)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "\n",
    "    ic_outputs = dict()\n",
    "    for i, c in enumerate(self.convs):\n",
    "      x = c(x)\n",
    "      print(\"debug\")\n",
    "      ic_outputs[i].append(self.heads[i](x)) #we put data through i-th internal head\n",
    "      ##### YOUR CODE HERE ########\n",
    "      # generate the outputs of each internal classifier and add it to\n",
    "      ######\n",
    "    return self.out(x), ic_outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "60XShaLHvnZZ"
   },
   "outputs": [],
   "source": [
    "#example initialization of net with 4 downsize steps and 4 internal classifiers\n",
    "net_heads = NetWithHeads([32, 64, 128, 256, 512], [1, 2, 3, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, number_of_epochs: int = 20, lr: float = 0.001):\n",
    "  net = net.to(device)\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "  epoch_progress = list(range(number_of_epochs))#tqdm(list(range(number_of_epochs)))\n",
    "  for i in epoch_progress:\n",
    "      train_loss = 0\n",
    "      y_train_predicted = []\n",
    "      y_train_true = []\n",
    "      net.train()\n",
    "      for iteration, (X_train, y_train) in enumerate(dl_train_in):#tqdm(enumerate(dl_train_in), f\"Training epoch {i}\", total=len(dl_train_in), leave=False):\n",
    "          # notice we are training / testing on dl_train_in - the same distribution of data!\n",
    "          X_train, y_train = [t.to(device) for t in [X_train, y_train]]\n",
    "          opt.zero_grad()\n",
    "          y_pred, = net(X_train)\n",
    "          loss = loss_fn(y_pred, y_train)\n",
    "          loss.backward()\n",
    "          opt.step()\n",
    "          train_loss += loss.item()\n",
    "          y_train_predicted.extend(y_pred.argmax(dim=1).cpu().numpy())\n",
    "          y_train_true.extend(y_train.cpu().numpy())\n",
    "\n",
    "\n",
    "      val_loss = 0\n",
    "      y_predicted = []\n",
    "      y_true = []\n",
    "\n",
    "      net.eval()\n",
    "      with torch.no_grad():\n",
    "          for iteration, (X_val, y_val) in enumerate(dl_test_in):#tqdm(enumerate(dl_test_in), f\"Val epoch {i}\",  total=len(dl_test_in), leave=False):\n",
    "              X_val, y_val = [t.to(device) for t in [X_val, y_val]]\n",
    "\n",
    "              y_pred, = net(X_val)\n",
    "              loss = loss_fn(y_pred, y_val)\n",
    "              val_loss += loss.item()\n",
    "              y_pred = y_pred.argmax(dim=1)\n",
    "              y_true.extend(y_val.cpu().numpy())\n",
    "              y_predicted.extend(y_pred.cpu().numpy())\n",
    "\n",
    "      train_acc = accuracy_score(y_train_true, y_train_predicted)\n",
    "      val_acc = accuracy_score(y_true, y_predicted)\n",
    "      print(f'epoch: {i}, train_acc: {train_acc: .2f}, train loss: {train_loss:.2f}, val_acc: {val_acc: .2f}, val loss: {val_loss:.2f} ')\n",
    "      torch.save(net.state_dict(), f'model.pt')\n",
    "      #epoch_progress.set_description(f'#Epoch: {i}, train loss: {train_loss:.2f}, train_acc: {train_acc:.2f}, val loss: {val_loss:.2f}, val_acc: {val_acc:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_class, model_path, device):\n",
    "    model = model_class()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_heads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(ece(net_heads, dl_test_in))\n\u001b[0;32m      4\u001b[0m draw_reliability_diagram(net_heads, dl_test_in, \u001b[38;5;28mstr\u001b[39m(i))\n",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36mtrain_net\u001b[1;34m(net, number_of_epochs, lr)\u001b[0m\n\u001b[0;32m     14\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m [X_train, y_train]]\n\u001b[0;32m     15\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 16\u001b[0m y_pred, \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_train)\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\Programy\\Anaconda\\envs\\uczenie_reprezentacji\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Programy\\Anaconda\\envs\\uczenie_reprezentacji\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36mNetWithHeads.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs):\n\u001b[0;32m     56\u001b[0m   x \u001b[38;5;241m=\u001b[39m c(x)\n\u001b[1;32m---> 58\u001b[0m   \u001b[43mic_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads[i](x)) \u001b[38;5;66;03m#we put data through i-th internal head\u001b[39;00m\n\u001b[0;32m     59\u001b[0m   \u001b[38;5;66;03m##### YOUR CODE HERE ########\u001b[39;00m\n\u001b[0;32m     60\u001b[0m   \u001b[38;5;66;03m# generate the outputs of each internal classifier and add it to\u001b[39;00m\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;66;03m######\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(x), ic_outputs\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "train_net(net_heads)\n",
    "\n",
    "print(ece(net_heads, dl_test_in))\n",
    "draw_reliability_diagram(net_heads, dl_test_in, str(i))\n",
    "draw_scores_histogram(net_heads, dl_test_in, str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, head_index,number_of_epochs: int = 20, lr: float = 0.001):\n",
    "  net = net.to(device)\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  opt = torch.optim.Adam(net.heads[head_index].parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  epoch_progress = list(range(number_of_epochs))#tqdm(list(range(number_of_epochs)))\n",
    "  for i in epoch_progress:\n",
    "      train_loss = 0\n",
    "      y_train_predicted = []\n",
    "      y_train_true = []\n",
    "      net.train()\n",
    "      for iteration, (X_train, y_train) in enumerate(dl_train_in):#tqdm(enumerate(dl_train_in), f\"Training epoch {i}\", total=len(dl_train_in), leave=False):\n",
    "          # notice we are training / testing on dl_train_in - the same distribution of data!\n",
    "          X_train, y_train = [t.to(device) for t in [X_train, y_train]]\n",
    "          opt.zero_grad()\n",
    "          y_pred = net(X_train)[1][head_index]\n",
    "          loss = loss_fn(y_pred, y_train)\n",
    "          loss.backward()\n",
    "          opt.step()\n",
    "          train_loss += loss.item()\n",
    "          y_train_predicted.extend(y_pred.argmax(dim=1).cpu().numpy())\n",
    "          y_train_true.extend(y_train.cpu().numpy())\n",
    "\n",
    "\n",
    "      val_loss = 0\n",
    "      y_predicted = []\n",
    "      y_true = []\n",
    "\n",
    "      net.eval()\n",
    "      with torch.no_grad():\n",
    "          for iteration, (X_val, y_val) in enumerate(dl_test_in):#tqdm(enumerate(dl_test_in), f\"Val epoch {i}\",  total=len(dl_test_in), leave=False):\n",
    "              X_val, y_val = [t.to(device) for t in [X_val, y_val]]\n",
    "\n",
    "              y_pred = net(X_val)[1][head_index]\n",
    "              loss = loss_fn(y_pred, y_val)\n",
    "              val_loss += loss.item()\n",
    "              y_pred = y_pred.argmax(dim=1)\n",
    "              y_true.extend(y_val.cpu().numpy())\n",
    "              y_predicted.extend(y_pred.cpu().numpy())\n",
    "\n",
    "      train_acc = accuracy_score(y_train_true, y_train_predicted)\n",
    "      val_acc = accuracy_score(y_true, y_predicted)\n",
    "      print(f'epoch: {i}, train_acc: {train_acc: .2f}, train loss: {train_loss:.2f}, val_acc: {val_acc: .2f}, val loss: {val_loss:.2f} ')\n",
    "      #epoch_progress.set_description(f'#Epoch: {i}, train loss: {train_loss:.2f}, train_acc: {train_acc:.2f}, val loss: {val_loss:.2f}, val_acc: {val_acc:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
